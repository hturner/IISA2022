<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Efficient Code</title>
    <meta charset="utf-8" />
    <meta name="author" content=" Dr Heather Turner Research Software Engineering Fellow, University of Warwick, UK " />
    <meta name="date" content="2022-12-30" />
    <script src="libs/header-attrs-2.19/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="extra.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Efficient Code
]
.author[
### <br>Dr Heather Turner<br>Research Software Engineering Fellow, University of Warwick, UK<br>
]
.date[
### 30 December 2022
]

---





class: inverse middle

# Memory management

---

# Overview

Objects created in R are stored in memory. This has the advantage that
objects can be accessed faster, but R slows down as the memory fills up.
Creating objects also takes time. Therefore

 - re-use temporary variables. The allocated storage will be re-used if
the vector has the same length.
 - save results for re-use, e.g. index variables
 - don't save intermediate results unnecessarily -- compute on-the-fly
 - remove large objects when no longer needed (with `rm()`)
 
---

# Basic data structures

Try to use the simplest data structure for your purpose
 - matrices vs. data frames 
 - character or integer vectors vs. factors
 - logical or integer vectors vs. numeric vectors
 - unnamed objects vs. named objects
    
It is especially important to use low-level structures for computation
- you can create richer objects as a final step before returning to the user.

???
L for integer

---

# Big Data

Modern computers have enough RAM to work with millions of records 
using standard functions.

Some packages to work more efficiently with big data:

 - **data.table** faster operations on data frames; read/write 
large CSVs
 - **feather**, **fst** read/write (parts of) binary files
 - **dplyr** manipulation of data in databases.
 - **bigmemory**, **biganalytics** faster matrix operations,
generalized linear models, kmeans

Parallelisation can also help, see later.

???
N.B. sparse matrices not as efficient as you might expect for general programming, may need big data for it to be important.

---

# Growing Objects

Adding to an object in a loop


```r
res &lt;- NULL
for (i in 1:5000) res &lt;- c(res, 1)
```
   
may force a copy to be made at each iteration, with each copy stored until the
loop has completed. 
   
It is far better to create an object of the necessary size first  


```r
res &lt;- numeric(5000)
for (i in seq_along(res)) res[i] &lt;- 1
```

---

# Copy-on-Change

R usually copies an object to make changes to it.

`tracemem` can be used to trace copies of an object


```r
z &lt;- NULL
for (i in 1:3){ z &lt;- c(z,1); print(tracemem(z)) }
```

```
# [1] "&lt;000001C6FCDDDD90&gt;"
# [1] "&lt;000001C6F91C9648&gt;"
# [1] "&lt;000001C6FC3C0BF8&gt;"
```

```r
z &lt;- numeric(2); print(tracemem(z))
```

```
# [1] "&lt;000001C6FD47D7F8&gt;"
```


```r
for (i in 1:2){z[i] &lt;- i;print(tracemem(z))}
```

```
# tracemem[0x000001c6fd47d7f8 -&gt; 0x000001c6f7f1db88]: eval eval eval_with_user_handlers withVisible withCallingHandlers handle timing_fn evaluate_call &lt;Anonymous&gt; evaluate in_dir in_input_dir eng_r block_exec call_block process_group.block process_group withCallingHandlers process_file &lt;Anonymous&gt; &lt;Anonymous&gt; do.call rebuild build force toJSON doTryCatch tryCatchOne tryCatchList tryCatch &lt;Anonymous&gt; handler doTryCatch tryCatchOne tryCatchList tryCatch try &lt;Anonymous&gt; evalq evalq doTryCatch tryCatchOne tryCatchList doTryCatch tryCatchOne tryCatchList tryCatch 
# [1] "&lt;000001C6F7F1DB88&gt;"
# [1] "&lt;000001C6F7F1DB88&gt;"
```

???

makes copy for each separate block of code
e.g. if run with above in one go interactively no copies
     if run in separate chunks 1 copy

---

# Benchmarking

There will usually be many ways to write code for a given task. To compare
alternatives, we can use benchmark the code.

If the code is more than a single expression, create wrappers for each alternative

```r
grow &lt;- function(n){
  res &lt;- NULL
  for (i in 1:n) res &lt;- c(res, 1)
  res
}
pre_specify &lt;- function(n){
  res &lt;- numeric(n)
  for (i in seq_along(res)) res[i] &lt;- 1
  res
}
```
---

# `bench::mark`

Then run the two alternatives with `bench::mark`. This function 
 - Runs each expression at least once and at most enough times to take 0.5s
 - Makes sure the two expressions return the same result!  
 

```r
library(bench)
(bm &lt;- bench::mark(grow(5000), pre_specify(5000)))
```

```
# Warning: Some expressions had a GC in every iteration; so filtering
# is disabled.
```

```
# # A tibble: 2 × 6
#   expression             min   median `itr/sec` mem_alloc `gc/sec`
#   &lt;bch:expr&gt;        &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;
# 1 grow(5000)          57.8ms   67.3ms      14.9    95.6MB    57.7 
# 2 pre_specify(5000)  155.2µs  181.5µs    4931.     56.2KB     8.00
```

* `GC` is the garbage collector which tidies up objects are deleted
* `itr/sec` is how many times the expression could be run per second

---

# Plotting benchmarks

Distribution tends to be right-skewed - focus on the median!



```r
plot(bm)
```

&lt;img src="02_efficient_code_files/figure-html/unnamed-chunk-1-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

# Scaling

Benchmarking can be difficult as the best option can depend on the size of the data, e.g. memory allocation can overshadow run time for small objects.

When thinking about how our code scales to bigger, we need to consider what we mean by "big"
 - number of rows or number of columns?
 - number of observations or number of factor levels?
 
---

# `bench::press()`
 
`bench::press()` can compare a function over  grid of parameters


```r
bench::press(
  n = c(10, 100),
  k = c(10, 1),
  bench::mark(gl(n, k, length = 1000))
)
```

```
# Running with:
#       n     k
```

```
# 1    10    10
```

```
# 2   100    10
```

```
# 3    10     1
```

```
# 4   100     1
```

```
# # A tibble: 4 × 8
#   expression                  n     k    min median itr/s…¹ mem_a…²
#   &lt;bch:expr&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;bch:&gt; &lt;bch:&gt;   &lt;dbl&gt; &lt;bch:b&gt;
# 1 gl(n, k, length = 1000)    10    10  6.2µs  7.9µs 119072.  4.39KB
# 2 gl(n, k, length = 1000)   100    10 14.7µs 18.9µs  51315. 11.05KB
# 3 gl(n, k, length = 1000)    10     1  5.4µs  6.9µs 137651.  3.95KB
# 4 gl(n, k, length = 1000)   100     1 11.2µs 14.5µs  66714.  7.53KB
# # … with 1 more variable: `gc/sec` &lt;dbl&gt;, and abbreviated variable
# #   names ¹​`itr/sec`, ²​mem_alloc
```

---

# Your Turn

Suppose we have a matrix of data and a two-level factor

```r
nr &lt;- 10
nc &lt;- 50
X &lt;- matrix(rnorm(nr * nc, 10, 3), nrow = nr)
grp &lt;- gl(2, 25)
```

Use `bench::mark()` to compare the following ways to find the coefficients of a linear model fitted to each row


```r
# one
res &lt;- vector("list", nr)
for(i in seq_len(nr)){
  res[[i]] &lt;- coef(lm(X[i,] ~ grp))
}
do.call("cbind", res)
# two
res2 &lt;- coef(lm(t(X) ~ grp))
```

---

# Fast options for common operations

* Sorting
 - Use `sort(x, partial = 1:10)` to get the top 10
 - Use `sort(x, decreasing = TRUE)` vs `rev(sort(x))`
* Generating numeric vectors
 - `seq.int()` vs `seq()` or `seq_along(x)`, `seq_len(n)` for special cases
 - `rep.int()` vs `rep()` or `rep_len(n)`
* `which.min()` and `which.max()` vs e.g. `which(x == min(x))`
* `anyNA(x)` vs `any(is.na(x))`

???
"int" stands for internal!

---

# For Loops

For loops are an intuitive way to write code, but can be very inefficient. 

`for` is a function, `:` or `seq_along` is another
function, each use of `[` is a call to a function, ..., so a loop
involves many nested function calls.

Therefore avoid for loops where possible, otherwise make as lean as 
possible, by taking whatever can be outside the loop.

---

# Vectorization

Vectorization is operating on vectors (or vector-like objects) rather than
individual elements and is generally faster.

Many operations in R are vectorized, e.g.

```r
x &lt;- 1:3
y &lt;- 3:1
x == y
```

```
# [1] FALSE  TRUE FALSE
```

```r
x + y
```

```
# [1] 4 4 4
```

---

# Vectorization and Matrices

Vectorization applies to matrices too, not only through matrix algebra


```r
M &lt;- matrix(1:4, nrow = 2, ncol = 2)
M + M
```

```
#      [,1] [,2]
# [1,]    2    6
# [2,]    4    8
```

but also vectorized functions


```r
M &lt;- M + .3
round(M)
```

```
#      [,1] [,2]
# [1,]    1    3
# [2,]    2    4
```

---

# Recycling

Vectorized functions will recycle shorter vectors to create vectors of the
same length


```r
1:4 + 0:1 + 2
```

```
# [1] 3 5 5 7
```

This is particularly useful for single values


```r
1:5 &gt; 1
```

```
# [1] FALSE  TRUE  TRUE  TRUE  TRUE
```

and for generating regular patterns


```r
paste0(rep(1:3, each = 2), c("a", "b"))
```

```
# [1] "1a" "1b" "2a" "2b" "3a" "3b"
```

---

# `ifelse`

`ifelse` is a vectorised version of `if`/`else`


```r
x &lt;- c(5, 2, 9, 12)
ifelse(x &gt; 6, 2 * x, 3 * x)
```

```
# [1] 15  6 18 24
```

Recycling is also very useful here


```r
x &lt;- 1:10
ifelse(x %% 2 == 0, 5, 12)
```

```
#  [1] 12  5 12  5 12  5 12  5 12  5
```

However indexing is more efficient than `ifelse`


```r
y &lt;- rep.int(12, 10)
y[x %% 2 == 0] &lt;- 5
y
```

```
#  [1] 12  5 12  5 12  5 12  5 12  5
```

---

# Logical operations

Logical operators such as `&amp;` and `|` are vectorized, e.g.


```r
x &lt;- c(1, 0.6, 1.2, 0.4, 0.5)
x &gt; 0.4 &amp; x &lt; 0.8
```

```
# [1] FALSE  TRUE FALSE FALSE  TRUE
```
If we only want to compare vectors of length 1 the operators `&amp;&amp;` and `||` are more efficient as they only compute the RHS if needed


```r
x[1] &gt; 0.4 &amp;&amp; x[1] &lt; 0.8
```

```
# [1] FALSE
```
Make sure the vectors are of length 1, otherwise only the first element is compared, without a warning


```r
x &gt; 0.4 &amp;&amp; x &lt; 0.8
```

```
# Warning in x &gt; 0.4 &amp;&amp; x &lt; 0.8: 'length(x) = 5 &gt; 1' in coercion to
# 'logical(1)'

# Warning in x &gt; 0.4 &amp;&amp; x &lt; 0.8: 'length(x) = 5 &gt; 1' in coercion to
# 'logical(1)'
```

```
# [1] FALSE
```


---

# `apply`
`apply` provides a way to apply a function to every row or column of a matrix

```r
M &lt;- matrix(1:20, 2, 10)
apply(M, 1, quantile, 0.75)
```

```
# [1] 14.5 15.5
```

```r
apply(M, 2, mean)
```

```
#  [1]  1.5  3.5  5.5  7.5  9.5 11.5 13.5 15.5 17.5 19.5
```

---

# `lapply`

`lapply` applies a given function to each element of a list

```r
l &lt;- list()
l$x &lt;- 1:3
l$y &lt;- 4:6
lapply(l, mean)
```

```
# $x
# [1] 2
# 
# $y
# [1] 5
```

---

# `sapply` and `vapply`

`sapply` acts similarly to `lapply`, but tries to simplify the result

```r
sapply(l, mean)
```

```
# x y 
# 2 5
```

It is better to use `vapply` in programming as it ensures the returned object is of the expected type (and is slightly faster)


```r
vapply(l, mean, numeric(1))
```

```
# x y 
# 2 5
```


---

# Matrix Methods 

Functions such as `apply` are very general. R provides fast
implementations for special cases

```r
colMeans(M)
```

```
#  [1]  1.5  3.5  5.5  7.5  9.5 11.5 13.5 15.5 17.5 19.5
```

```r
rowMeans(M)
```

```
# [1] 10 11
```

```r
colSums(M)
```

```
#  [1]  3  7 11 15 19 23 27 31 35 39
```

```r
rowSums(M)
```

```
# [1] 100 110
```

---

# More Matrix Methods
`rowsum` sums over rows within each level of a grouping variable

```r
M &lt;- matrix(1:8, 4)
rowsum(M, rep(1:2, each = 2))
```

```
#   [,1] [,2]
# 1    3   11
# 2    7   15
```
The packages `matrixStats` provides even more "matricized"
operations, including medians and standard deviations

```r
library(matrixStats); colMedians(M)
```

```
# [1] 2.5 6.5
```

```r
rowSds(M)
```

```
# [1] 2.828 2.828 2.828 2.828
```

---

class: inverse middle

# Parallelisation

---

# Parallelisation

Most functions in R run on a single core of your machine. The 
**parallel** package, part of the default R distribution, provides 
parallel versions of the `apply`-type functions.

Parallelisation is most straight-forward to implement for
*embarrassingly parallel* problems, such as applying a function to
elements of a list.

The first step is to make a cluster from the available cores, here 2

```r
library(parallel)
clus &lt;- makeCluster(2)
```
You can use `parallel::detectCores() - 1` on your own computer; `parallelly::availableCores() - 1` is safer to use in general.

---

# parApply on Multiple Cores

`parApply` is used exactly as `apply`, but has an additional
argument to specify the cluster on which to run the code

```r
res &lt;- parApply(clus, M, 1, quantile, 0.75)
```
There are also special versions for applying to rows (R) and cols (C)

```r
res &lt;- parRapply(clus, M, quantile, 0.75)
res &lt;- parCapply(clus, M, mean)
```

---

# parLapply and parSapply

Similarly `parLapply` and `parSapply` mirror `lapply` and `sapply`

```r
parLapply(clus, l, mean)
```

```
# $x
# [1] 2
# 
# $y
# [1] 5
```

```r
parSapply(clus, l, mean)
```

```
# x y 
# 2 5
```
Any number of R commands can be run after the cluster has been created. At the end, run

```r
stopCluster(clus)
```

---

# Your Turn

The **efficient** package contains a function to simulate a game of snakes and 
ladders, returning the number of rolls required to win.


Parallelise the following code:

```r
library(efficient)
N &lt;- 10
nrolls &lt;- sapply(seq_len(N), snakes_ladders)
```

---

# General Principles
Try to use vectorized functions where possible.

Otherwise use the `apply` family (and parellelise if necessary). Custom
functions will often be useful here to pass to `apply` etc.

Try to keep for loops for true iterative computations or tasks that are fast
in any case (optimizing code takes time!)

---

# References

Good references on optimizing R code

Wickham, H, _Advanced R_ (2nd edn), _Improving performance section_, https://adv-r.hadley.nz/perf-improve.html

Gillespie, C and Lovelace, R, _Efficient R programming_, https://csgillespie.github.io/efficientR/
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "googlecode",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
